{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14920d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84b458",
   "metadata": {},
   "source": [
    "# 3. Mean Field Approximation and Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb20ecb",
   "metadata": {},
   "source": [
    "## Part 1: Exact Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611b8fc",
   "metadata": {},
   "source": [
    "Given a binary variable Markov Random Field with parameter $\\beta$: $p(x) = Z^{-1}\\prod_{i>j}\\phi(x_i,x_j)$, defined on the n x n lattice with $\\phi(x_i,x_j) = e^{\\beta I[x_i=x_j]}$ for i a neighbour of j on the lattice and i > j.\n",
    "\n",
    "You will need to compute the joint probability distribution of the top and bottom nodes of the rightmost column of the 10 Ã— 10 lattice for $\\beta = 4$, $\\beta = 1$, and $\\beta = 0.01.$ In other words, need to find probability table for $P(x_{1,10}, x_{10,10})$\n",
    "\n",
    "Perform exact inference, using techniques from Exercise 6.7. That is, treat\n",
    "each column as one variable with 2n states and perform message passing\n",
    "on the induced factor-graph. [5 marks]\n",
    "\n",
    "---- \n",
    "The joint for this MRF will be $P(V_1, V_2,.. V_{10}) \\propto \\Phi_1(V_1) * \\Psi_1(V_1, V_2)* \\Phi_2(V_2) *...* \\Psi_{9}(V_9, V_{10})* \\Phi_{10}(V_{10})$\n",
    "\n",
    "To find this, we need to find $\\Phi_t(V_t)$ (the internal potentials, describe verticals) and $\\Psi_t(V_t, V_{t+1})$ (the transition potentials, describe horizontal, pairwise). $\\Phi_t(V_t)$ will be a vector with $2^{10}=1024$ states, and $\\Psi_t(V_t,V_{t+1})$ will be a matrix with $2^{10}$ x $2^{10}=1024$ x $1024$ states describing the probability of transition from one of the 1024 states in $V_t$ to one of the 1024 states in $V_{t+1}$.\n",
    "\n",
    "We can define $\\Phi_t(V_t) = \\prod_{i=1}^{9}\\phi(x_{i,t},x_{i+1,t})$, and $\\Psi_t(V_t, V_{t+1}) = \\prod_{i=1}^{10}\\phi(x_{i,t},x_{i,t+1})$.\n",
    "\n",
    "Then, to calculate $P(x_{1,10}, x_{10,10})$, we will need to use the Sum-Product algorithm, where  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dc1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(beta, xi, xj):\n",
    "    \"\"\"\n",
    "    Function to calculate phi(xi,xj) for a given beta\n",
    "    \"\"\"\n",
    "    indicator = np.sum(xi == xj)\n",
    "    return np.exp(beta * indicator)\n",
    "\n",
    "\n",
    "def calculate_Phi_Psi(N, K, states, beta):\n",
    "    \"\"\"\n",
    "    Function to calculate the potentials Phi(Vt) and Psi(Vt, Vt+1) for an \n",
    "    N x N lattice Markov Random Field. \n",
    "    \"\"\"\n",
    "    # create 2^N x N matrix of all potential values of binary vector Vt (one column of lattice)\n",
    "    all_combinations_tuple = product(states, repeat=N)\n",
    "    V_t_matrix = np.array(list(all_combinations_tuple))\n",
    "\n",
    "    # initialize Phi_t(Vt), this will be a 2^10 x 2^10 array\n",
    "    Phi_t = np.zeros(K)\n",
    "\n",
    "    # for each potential column state k of Vt, find Phi(Vt)\n",
    "    for k in range(K):\n",
    "        # this will be a single state of vector Vt of shape (N, )\n",
    "        V_t_state = V_t_matrix[k, :]\n",
    "        # calculate the value of Phi(Vt) for given state\n",
    "        Phi_t[k] = phi(beta,V_t_state[:-1],V_t_state[1:])\n",
    "\n",
    "    # initialize Psi_t(Vt, Vt+1), this will be a 2^10 x 2^10 matrix \n",
    "    Psi_t = np.zeros((K, K))\n",
    "\n",
    "    # for each potential column k_t of state Vt and each potential\n",
    "    # column k_tplus1 of Vt+1, find Psi(Vt, Vt+1)\n",
    "    for k_t in range(K):\n",
    "        # same single state of vector Vt of shape (N, ) as above\n",
    "        V_t_state = V_t_matrix[k_t, :]\n",
    "        for k_tplus1 in range(K):\n",
    "            # single state of vector Vt+1 of shape (N, )\n",
    "            V_tplus1_state = V_t_matrix[k_tplus1, :]\n",
    "            Psi_t[k_t, k_tplus1] = phi(beta, V_t_state, V_tplus1_state)\n",
    "\n",
    "    print(f'Phi_t(Vt) Shape: {Phi_t.shape}')\n",
    "    print(f'Psi_t(Vt, Vt+1) Shape: {Psi_t.shape}\\n')\n",
    "\n",
    "    return (Phi_t, Psi_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a95f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_propogation(Phi, Psi, T, i, j, V_t_matrix, N, K, states):\n",
    "    \"\"\"\n",
    "    Belief propogation to calculate joint probability of P(Xi,T, Xj,T).\n",
    "    \"\"\"\n",
    "    # initialize alphas (forward pass), a vector of length K (column states)\n",
    "    alphas = np.zeros((T, K))\n",
    "    alphas[0] = Phi\n",
    "    alphas[0] /= np.sum(alphas[0])\n",
    "\n",
    "    # for each timestep from 1 to T...\n",
    "    for t in range(1, T):\n",
    "        # message from t-1 and potentials for Vt\n",
    "        alpha_t = Phi * (Psi.T @ alphas[t-1]) # matrix of shape (K x K) @ vector of shape (K, ) = vector of shape (K, )\n",
    "        # find normalization constant for t\n",
    "        Z_t = np.sum(alpha_t)\n",
    "        alphas[t] = alpha_t/Z_t\n",
    "\n",
    "    # backward pass\n",
    "    betas = np.zeros((T, K))\n",
    "    betas[T-1] = np.ones(K)\n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        # message from t+1 to t for Vts\n",
    "        beta_t = Psi @ (betas[t+1] * Phi )\n",
    "        # find normalization constant for t\n",
    "        Z_t = np.sum(beta_t)\n",
    "        betas[t] = beta_t/Z_t\n",
    "\n",
    "    # calculate belief vectors for Vt at final timestep t=T, shape (K, )\n",
    "    belief_T = (alphas[T-1] * betas[T-1])/np.sum((alphas[T-1] * betas[T-1]))\n",
    "\n",
    "    # to get joint prob, need to find relevant belief vectors (where states line up with\n",
    "    # desired Xi,j\n",
    "    joint_distribution = np.zeros((len(states),len(states)))\n",
    "    for idx1, s1 in enumerate(states):\n",
    "        for idx2, s2 in enumerate(states):\n",
    "            # find indices where \n",
    "            indices = np.logical_and(V_t_matrix[:,i-1] == s1, V_t_matrix[:,j-1] == s2)\n",
    "\n",
    "            unnormalized_joint = np.sum(belief_T[indices])\n",
    "\n",
    "            joint_distribution[idx1, idx2] = unnormalized_joint\n",
    "    return joint_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121b659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1024 x 1024 = 1048576 potential states for the 10 x 10 lattice of the binary Markov Random Field.\n",
      "\n",
      "To reduce computational complexity, we will consider 10 vectors of length 10, each with 1024 potential states.\n",
      "\n",
      "Phi_t(Vt) Shape: (1024,)\n",
      "Psi_t(Vt, Vt+1) Shape: (1024, 1024)\n",
      "\n",
      "Joint Probability Distribution of P(X1,10, X10,10) for Beta = 4:\n",
      "[[4.99622685e-01 3.77315354e-04]\n",
      " [3.77315354e-04 4.99622685e-01]]\n",
      "Phi_t(Vt) Shape: (1024,)\n",
      "Psi_t(Vt, Vt+1) Shape: (1024, 1024)\n",
      "\n",
      "Joint Probability Distribution of P(X1,10, X10,10) for Beta = 1:\n",
      "[[0.25974154 0.24025846]\n",
      " [0.24025846 0.25974154]]\n",
      "Phi_t(Vt) Shape: (1024,)\n",
      "Psi_t(Vt, Vt+1) Shape: (1024, 1024)\n",
      "\n",
      "Joint Probability Distribution of P(X1,10, X10,10) for Beta = 0.01:\n",
      "[[0.25 0.25]\n",
      " [0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "# define dimensions of square lattice\n",
    "N = 10\n",
    "betas = [4, 1, 0.01]\n",
    "\n",
    "# define states of xi,j to be [0,1]\n",
    "states = [0,1]\n",
    "# column states (K)\n",
    "K = len(states)**N\n",
    "\n",
    "print(f'There are {K} x {K} = {K**2} potential states for the {N} x {N} lattice of the binary Markov Random Field.\\n')\n",
    "\n",
    "print(f'To reduce computational complexity, we will consider {N} vectors of length {N}, each with {K} potential states.\\n')\n",
    "\n",
    "# create 2^N x N matrix of all potential values of binary vector Vt (one column of lattice)\n",
    "all_combinations_tuple = product(states, repeat=N)\n",
    "V_t_matrix = np.array(list(all_combinations_tuple))\n",
    "\n",
    "# loop through each value of beta\n",
    "for beta in betas:\n",
    "    Phi_t, Psi_t = calculate_Phi_Psi(N=N, K=K, states=states, beta=beta)\n",
    "\n",
    "    p_joint = belief_propogation(Phi_t, Psi_t, T=3, i=1, j=10, V_t_matrix=V_t_matrix, N=N, K=K, states=states)\n",
    "    print(f'Joint Probability Distribution of P(X1,10, X10,10) for Beta = {beta}:')\n",
    "    print(p_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3932d3bc",
   "metadata": {},
   "source": [
    "$\\beta$ = 4\n",
    "\n",
    "| $\\beta = 4$  | $P(x_{10,10}) = 0$| $P(x_{10,10}) =1$|\n",
    "| -------- | ------- | ------- |\n",
    "| $P(x_{1,10}) =0$        | 0.4997 | 0.0004 |\n",
    "| $P(x_{1,10}) =1$        | 0.0004 | 0.4997 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad82dce",
   "metadata": {},
   "source": [
    "$\\beta$ = 1\n",
    "\n",
    "| $\\beta = 4$  | $P(x_{10,10}) = 0$| $P(x_{10,10}) =1$|\n",
    "| -------- | ------- | ------- |\n",
    "| $P(x_{1,10}) =0$        | 0.2808 | 0.2192 |\n",
    "| $P(x_{1,10}) =1$        | 0.2192 | 0.2808 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d2c92",
   "metadata": {},
   "source": [
    "$\\beta$ = 0.01\n",
    "\n",
    "| $\\beta = 4$  | $P(x_{10,10}) = 0$| $P(x_{10,10}) =1$|\n",
    "| -------- | ------- | ------- |\n",
    "| $P(x_{1,10}) =0$        | 0.25 | 0.25 |\n",
    "| $P(x_{1,10}) =1$        | 0.25 | 0.25 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphicalModelsCW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
